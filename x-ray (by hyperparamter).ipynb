{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810},{"sourceId":192252820,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport random\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers, models\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import load_model\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom tensorflow import keras\nimport keras_tuner\n\n# Function to load and preprocess images\ndef loading_preprossing(path):\n    img_list = []\n    for img_path in os.listdir(path):\n        img = cv2.imread(os.path.join(path, img_path))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (255, 255))\n        img = img / 255.0\n        img_list.append(img)\n    return img_list\n\n# Load the datasets\nnormal_images = loading_preprossing('/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL')\npneumonia_images = loading_preprossing('/kaggle/input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA')\n\n# Randomly sample the specified number of images from each class\nnormal_samples = random.sample(normal_images, 1340)\npneumonia_samples = random.sample(pneumonia_images, 2000)\n\n# Combine the datasets\ntrain_images = normal_samples + pneumonia_samples\ntrain_labels = [0] * len(normal_samples) + [1] * len(pneumonia_samples)\n\n# Convert to numpy arrays\ntrain_images = np.array(train_images)\ntrain_labels = np.array(train_labels)\n\n# Split the dataset into training and testing sets\nx_train, x_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n\n# Convert labels to categorical (one-hot encoding)\nnum_classes=2\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(hp):\n    model=models.Sequential()\n    model.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu',input_shape=(255,255,3)))\n    model.add(layers.MaxPool2D(pool_size=(3,3)))\n    model.add(layers.Dropout(rate=.25))\n    model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(x_train.shape[1],)))\n    model.add(layers.MaxPool2D(pool_size=(3,3)))\n    \n    model.add(layers.Flatten())\n    for i in range(hp.Int('num_layers',1,5)):\n        model.add(layers.Dense(units=hp.Int(f\"units{i}\",min_value=32,max_value=512,step=64),\n                              activation='relu'))\n        model.add(layers.Dense(units=hp.Int(f\"units{i}\",min_value=32,max_value=512,step=32),\n                              activation='relu'))\n    model.add(layers.Dense(2,'softmax'))\n    learning_rate=hp.Float('lr',min_value=1e-4, max_value=1e-2, sampling=\"log\")\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"])\n    return model\nbuild_model(keras_tuner.HyperParameters())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hp=keras_tuner.HyperParameters()\nprint(hp.Int(\"units\",min_value=32,max_value=512,step=32))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner=keras_tuner.RandomSearch(hypermodel=build_model,\n                              objective='val_accuracy',\n                              max_trials=3,\n                              executions_per_trial=2\n                              )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search_space_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search(x_train,y_train,epochs=5,validation_data=(x_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models=tuner.get_best_models(num_models=2)\nbest_model=models[0]\nbest_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.results_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import models\nfrom kerastuner import HyperParameters\n\nbest_hp = tuner.get_best_hyperparameters(5) [0]\n\nbest_hp.values\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tuner.hypermodel.build(best_hp)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x=x_train,y=y_train,epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the loaded model on test data\ntest_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\nprint(f'\\nTest accuracy: {test_acc}')\nprint(f'\\nTest loss: {test_loss}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_class1=loading_preprossing('/kaggle/input/chest-xray-pneumonia/chest_xray/test/NORMAL')\ntest_class2=loading_preprossing('/kaggle/input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_class1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_list=test_class1+test_class2\ntest_label=[0]*len(test_class1)+[1]*len(test_class2)\nprint('the label lenght: ',len(test_label))\nprint('the train list: ',len(test_list))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_list=np.array(test_list)\nPreds=model.predict(test_list)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=np.argmax(np.round(Preds),axis=1)\npreds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf=pd.DataFrame({'real':test_label,'predicted':preds})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate accuracy\naccuracy = accuracy_score(test_label,preds)\nprint(f'Accuracy: {accuracy}')\n\n# Generate a classification report\nclass_report = classification_report(test_label,preds, target_names=['Normal', 'Pneumonia'])\nprint('Classification Report:\\n', class_report)\n\n# Generate a confusion matrix\nconf_matrix = confusion_matrix(test_label,preds)\nprint('Confusion Matrix:\\n', conf_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('final exp.h5')\nprint('save')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}